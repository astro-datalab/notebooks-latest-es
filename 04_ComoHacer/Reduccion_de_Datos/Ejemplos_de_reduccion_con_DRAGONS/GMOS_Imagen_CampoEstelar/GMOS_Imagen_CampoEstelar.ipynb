{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__nbid__ = '0040'\n",
    "__author__ = 'Brian Merino <brian.merino@noirlab.edu>, Vinicius Placco <vinicius.placco@noirlab.edu>'\n",
    "__version__ = '20241209' # yyyymmdd; Versión DataSpamp de este notebook\n",
    "__keywords__ = ['gmos','gemini','stars','dragons']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción de fotometría de campo estrellado Gemini GMOS usando Dragons Python API\n",
    "#### Adaptado de https://dragons.readthedocs.io/projects/gmosimg-drtutorial/en/v3.2.1/ex1_gmosim_starfield_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a class=\"anchor\" id=\"attribution\"></a>\n",
    "# Avisos Legales y atribuciones\n",
    "\n",
    "Avisos Legales\n",
    "-----------\n",
    "Tome en cuenta que usar el Astro Data Lab constituye un acuerdo con nuestros [Avisos Legales](https://datalab.noirlab.edu/disclaimers.php) mínimos.\n",
    "\n",
    "Reconocimientos\n",
    "---------------\n",
    "Si ud. usa el **Astro Data Lab** en sus publicaciones de investigación, por favor incluya el siguiente texto en la sección de Reconocimientos de su publicaciones:\n",
    "\n",
    "_Esta investigación utiliza servicios de datos proveeidos por el Astro Data Lab, el cual es parte del Programa \"Community Science and Data Center\" (CSDC) (Centro de Ciencia Comunitaria y Datos) del NSF NOIRLab. NOIRLab es operado por la \"Association of Universities for Research in Astronomy (AURA), Inc.\"(Asociación de Universidaddes para la Investigación en Astronomía, Inc.), bajo un acuerdo de cooperación con la \"U.S. National Science Foundation\" (Fundación Nacional de Ciencia de los EE. UU.)._\n",
    "\n",
    "Si utiliza **SPARCL junto con la plataforma de Astro Data Lab** (por medio de JupyterLab, línea de comando o interfaz de la web) en su publicación de investigación, por favor incluya el siguiente texto en la sección de Reconocimientos de su publicaciones:\n",
    "\n",
    "_Esta investigación utiliza servicios o datos proporcionados por el \"SPectra Analysis and Retrievable Catalog Lab\" (SPARCL) (Laboratorio de Análisis y Catálogo Recuperable de Espectros) y el Astro Data Lab, ambos pertenecientes al Programa \"Community Science and Data Center\" (CSDC) (Centro de Ciencia Comunitaria y Datos) de NSF NOIRLab. NOIRLab es operado por la \"Association of Universities for Research in Astronomy (AURA), Inc.\" (Asociación de Universidades para la Investigación en Astronomía, Inc.), bajo un acuerdo de cooperación con la \"U.S. National Science Foundation\" (Fundación Nacional de Ciencia de los EE. UU.)._\n",
    "\n",
    "En cualquiera de los casos, **por favor cite las siguientes publicaciones**:\n",
    "\n",
    "* Publicación del concepto de Data Lab: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Descripción general del Astro Data Lab: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411.\n",
    "\n",
    "Si hace referencia al Jupyterlab / Jupyter notebooks de Data Lab, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097.\n",
    "\n",
    "Si publica en una revista de la AAS, agregue también la palabra clave `\\facility{Astro Data Lab}`\n",
    "\n",
    "Y si está usando SPARCL, por vor agregue también `\\software{SPARCL}` y cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576.\n",
    "\n",
    "La biblioteca de NOIRLab mantiene [listas de reconocimientos apropiados](https://noirlab.edu/science/about/scientific-acknowledgments) para usar cuando se hacen publicaciones utilizando los recursos, servicios o datos del Laboratorio.\n",
    "\n",
    "---- **Versión en Inglés** ----\n",
    "\n",
    "\n",
    "# Disclaimer & attribution\n",
    "\n",
    "Disclaimers\n",
    "-----------\n",
    "Note that using the Astro Data Lab constitutes your agreement with our minimal [Disclaimers](https://datalab.noirlab.edu/disclaimers.php).\n",
    "\n",
    "Acknowledgments\n",
    "---------------\n",
    "If you use **Astro Data Lab** in your published research, please include the text in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the Astro Data Lab, which is part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "If you use **SPARCL jointly with the Astro Data Lab platform** (via JupyterLab, command-line, or web interface) in your published research, please include this text below in your paper's Acknowledgments section:\n",
    "\n",
    "_This research uses services or data provided by the SPectra Analysis and Retrievable Catalog Lab (SPARCL) and the Astro Data Lab, which are both part of the Community Science and Data Center (CSDC) Program of NSF NOIRLab. NOIRLab is operated by the Association of Universities for Research in Astronomy (AURA), Inc. under a cooperative agreement with the U.S. National Science Foundation._\n",
    "\n",
    "In either case **please cite the following papers**:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://doi.org/10.1117/12.2057445\n",
    "\n",
    "* Astro Data Lab overview: Nikutta et al., \"Data Lab - A Community Science Platform\", Astronomy and Computing, 33, 2020, https://doi.org/10.1016/j.ascom.2020.100411\n",
    "\n",
    "If you are referring to the Data Lab JupyterLab / Jupyter Notebooks, cite:\n",
    "\n",
    "* Juneau et al., \"Jupyter-Enabled Astrophysical Analysis Using Data-Proximate Computing Platforms\", CiSE, 23, 15, 2021, https://doi.org/10.1109/MCSE.2021.3057097\n",
    "\n",
    "If publishing in a AAS journal, also add the keyword: `\\facility{Astro Data Lab}`\n",
    "\n",
    "And if you are using SPARCL, please also add `\\software{SPARCL}` and cite:\n",
    "\n",
    "* Juneau et al., \"SPARCL: SPectra Analysis and Retrievable Catalog Lab\", Conference Proceedings for ADASS XXXIII, 2024\n",
    "https://doi.org/10.48550/arXiv.2401.05576\n",
    "\n",
    "The NOIRLab Library maintains [lists of proper acknowledgments](https://noirlab.edu/science/about/scientific-acknowledgments) to use when publishing papers using the Lab's facilities, data, or services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"importaciones\"> </a>\n",
    "# Importar bibliotecas de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from gempy.adlibrary import dataselect\n",
    "from gempy.utils import logutils\n",
    "\n",
    "from recipe_system import cal_service\n",
    "from recipe_system.reduction.coreReduce import Reduce\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Preparar\"> </a>\n",
    "# Prepare el directorio de trabajo\n",
    "\n",
    "Si tiene algún archivo intermedio que se creó al ejecutar este código en el pasado, deberá eliminarlos de su directorio de trabajo. La siguiente celda define una función de limpieza que eliminará todos los archivos de ajuste de su directorio de trabajo. Esta función se volverá a llamar al final del tutorial, dejándote solo con el producto final. Por defecto, esta función eliminará todos los archivos en el directorio de trabajo. Si hay archivos que se han reducido previamente que le gustaría conservar, establezca `save_reduced = 1` al llamar a la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(save_reduced=0):\n",
    "    # ¿El directorio de calibraciones ya existe?\n",
    "    caldb_Exist = os.path.exists('./calibrations') \n",
    "    \n",
    "    if caldb_Exist:\n",
    "        shutil.rmtree('./calibrations', ignore_errors=True)\n",
    "\n",
    "    # Eliminar archivos de registro y lista existentes.\n",
    "    work_dir_path = os.getcwd()\n",
    "    work_dir = os.listdir(work_dir_path)\n",
    "\n",
    "    for item in work_dir:\n",
    "        if item.endswith(\".log\") or item.endswith(\".list\"):\n",
    "            os.remove(os.path.join(work_dir_path, item))\n",
    "    \n",
    "    # A continuación, eliminaremos todos los archivos de ajuste existentes, excepto los archivos reducidos previamente, dependiendo de lo que establezca save_reduced.\n",
    "    if save_reduced:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        save = dataselect.select_data(all_files_0, [], ['PROCESSED'])\n",
    "        \n",
    "        for s in save:\n",
    "            os.remove(os.path.join(work_dir_path,s))\n",
    "\n",
    "    else:\n",
    "        all_files_0 = glob.glob('*.fits')\n",
    "        for a in all_files_0:\n",
    "            os.remove(os.path.join(work_dir_path,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(save_reduced=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Acerca\"> </a>\n",
    "# Sobre el conjunto de datos\n",
    "\n",
    "Los datos utilizados para este tutorial son una secuencia aturdida en un campo estrellado.\n",
    "\n",
    "La siguiente tabla contiene un resumen del conjunto de datos:\n",
    "\n",
    "\n",
    "| Tipo de observación | Nombre del archivo (s) | Propósito y exposición (segundos) |\n",
    "| : --- | : --- | : ---: |\n",
    "| Ciencia | N20170614S0201-205 | 10 s, banda I |\n",
    "| Sesgo | N20170613S0180-184 |  |\n",
    "| Sesgo | N20170615S0534-538 |  |\n",
    "| Twilight Flats | N20170702S0178-182 | 40 a 16 s, I-Band |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"descargar_data\"> </a>\n",
    "# Descargar los datos\n",
    "\n",
    "Descarga de imágenes de banda I del Archivo de Géminis al directorio de trabajo actual. Este paso solo necesita ser ejecutado una vez.\n",
    "\n",
    "Si ejecuta este notebook por primera vez y necesita descargar el conjunto de datos, configure la variable \"download = true\". El notebook no se volverá a descargar el conjunto de datos si está configurado en falso. Esto se volverá particularmente útil si ejecuta los notebooks más de una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# Crear archivo que enumera se ajuste a los archivos a descargar\n",
    "echo \"\\\n",
    "http://archive.gemini.edu/file/N20170613S0180.fits\n",
    "http://archive.gemini.edu/file/N20170613S0181.fits\n",
    "http://archive.gemini.edu/file/N20170613S0182.fits\n",
    "http://archive.gemini.edu/file/N20170613S0183.fits\n",
    "http://archive.gemini.edu/file/N20170613S0184.fits\n",
    "http://archive.gemini.edu/file/N20170614S0201.fits\n",
    "http://archive.gemini.edu/file/N20170614S0202.fits\n",
    "http://archive.gemini.edu/file/N20170614S0203.fits\n",
    "http://archive.gemini.edu/file/N20170614S0204.fits\n",
    "http://archive.gemini.edu/file/N20170614S0205.fits\n",
    "http://archive.gemini.edu/file/N20170615S0534.fits\n",
    "http://archive.gemini.edu/file/N20170615S0535.fits\n",
    "http://archive.gemini.edu/file/N20170615S0536.fits\n",
    "http://archive.gemini.edu/file/N20170615S0537.fits\n",
    "http://archive.gemini.edu/file/N20170615S0538.fits\n",
    "http://archive.gemini.edu/file/N20170702S0178.fits\n",
    "http://archive.gemini.edu/file/N20170702S0179.fits\n",
    "http://archive.gemini.edu/file/N20170702S0180.fits\n",
    "http://archive.gemini.edu/file/N20170702S0181.fits\n",
    "http://archive.gemini.edu/file/N20170702S0182.fits\\\n",
    "\" > gmos_im_star.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "download=\"True\"\n",
    "\n",
    "if [ $download == \"True\" ]; then\n",
    "    wget --no-check-certificate -N -q -i gmos_im_star.list\n",
    "\n",
    "else\n",
    "    echo \"Skipping download. To download the data set used in this notebook, set download=True.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"dragons_logger\"> </a>\n",
    "# Configuración del Logger Dragons\n",
    "\n",
    "Dragons viene con un administrador de calibración local que utiliza las mismas reglas de asociación de calibración que el archivo del Observatorio Géminis. Esto permite reducir las solicitudes a una base de datos local de peso ligero para las calibraciones procesadas que coinciden cuando sea necesario para reducir un conjunto de datos.\n",
    "\n",
    "Esto le dice al sistema dónde colocar la base de datos de calibración. Esta base de datos realizará un seguimiento de las calibraciones procesadas que le enviaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logutils.config(file_name='gmos_data_reduction.log')\n",
    "caldb = cal_service.set_local_database()\n",
    "caldb.init(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('N2017*[0-9].fits')\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"FASCOR\" ID = \"FILE_LISTS\"> </a>\n",
    "# Crear listas de archivos\n",
    "\n",
    "Este conjunto de datos contiene marcos de ciencia y calibración. Para algunos programas, podría tener diferentes objetivos observados y tiempos de exposición dependiendo de cómo organice sus datos sin procesar.\n",
    "\n",
    "La tubería de reducción de datos de Dragons no organiza los datos por usted. Tienes que hacerlo. Dragons proporciona herramientas para ayudarlo con eso.\n",
    "\n",
    "El primer paso es crear listas que se utilizarán en el proceso de reducción de datos. Para eso, usamos DataSelect. Consulte el [DataSElect](https://dragons.readthedocs.io/projects/recipe-system-users-manual/en/stable/supptools/dataselect.html?highlight=dataSelect) documentación para obtener detalles sobre su uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lista de prejuicios **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_biases = dataselect.select_data(\n",
    "    all_files,\n",
    "    ['BIAS'],\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lista de pisos **\n",
    "\n",
    "Si su conjunto de datos tiene pisos obtenidos con más de un filtro, puede agregar la expresión --expr 'filtre_name == \"i\" para obtener solo los pisos obtenidos dentro de la banda I. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_flats = dataselect.select_data(\n",
    "     all_files,\n",
    "     ['FLAT'],\n",
    "     [],\n",
    "     dataselect.expr_parser('filter_name==\"i\"')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lista de datos científicos **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_science = dataselect.select_data(\n",
    "    all_files,\n",
    "    [],\n",
    "    ['CAL'],\n",
    "    dataselect.expr_parser('(observation_class==\"science\" and filter_name==\"i\")')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Master_bias\"> </a>\n",
    "# Crea un sesgo maestro\n",
    "Comenzamos la reducción de datos creando un sesgo maestro para los datos científicos. Se puede crear y agregar a la base de datos de calibración utilizando los comandos a continuación. El sesgo maestro tendrá el nombre del primer sesgo con el sufijo _bias.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_bias = Reduce()\n",
    "reduce_bias.files.extend(list_of_biases)\n",
    "reduce_bias.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Master_flat\"> </a>\n",
    "# Crea un campo plano maestro\n",
    "\n",
    "Las imágenes planas crepusculares se utilizan para producir un plano de maestros de imágenes y el resultado se agrega a la base de datos de calibración.\n",
    "\n",
    "El Master Flat tendrá el nombre del primer archivo plano de Twilight con el sufijo _flat.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_flats = Reduce()\n",
    "reduce_flats.files.extend(list_of_flats)\n",
    "reduce_flats.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Reduce_science\"> </a>\n",
    "# Reducir las imágenes de la ciencia\n",
    "\n",
    "Una vez que nuestros archivos de calibración se procesan y se agregan a la base de datos, podemos ejecutar reducir en nuestros datos científicos.\n",
    "\n",
    "Este comando generará sesgo y archivos planificados y los apilará. Si se necesita un marco marginal, este comando aplicará la corrección. La imagen apilada tendrá el sufijo _stack.\n",
    "\n",
    "Las unidades de pila de salida están en electrones (palabra clave de encabezado Bunit = electrones). La pila de salida se almacena en un archivo de ajuste de extensión múltiple (MEF). La señal científica está en la extensión \"Sci\", la varianza está en la extensión \"var\" y el plano de calidad de datos (máscara) está en la extensión \"DQ\".\n",
    "\n",
    "Cada imagen científica reducida tendrá el nombre original con el sufijo _image.fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_science = Reduce()\n",
    "reduce_science.files.extend(list_of_science)\n",
    "reduce_science.runr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<A class = \"Anchor\" id = \"Imagen de visualización\"> </y>\n",
    "# Muestra la imagen apilada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"N20170614S0201_image.fits\"\n",
    "hdu_list = fits.open(image_file)\n",
    "wcs = WCS(hdu_list[1].header)\n",
    "hdu_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fits.getdata(image_file, ext=1)\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(projection=wcs)\n",
    "plt.imshow(image_data,cmap='gray',norm=LogNorm(vmin=0.01, vmax=1000000),origin='lower')\n",
    "plt.xlabel('Ascensión derecha [HH: MM: SS]',fontsize=14,fontweight='atrevido')\n",
    "plt.ylabel('Declinación [grado]',fontsize=14,fontweight='atrevido')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class = \"Anchor\" id = \"Clean-Up\"> </a>\n",
    "# Opcional: elimine las calibraciones duplicadas y elimine los datos sin procesar (líneas de incommento antes de ejecutar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_up (save_reduced = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRAGONS-3.2.2 (DL,Py3.10.14)",
   "language": "python",
   "name": "dragons-3.2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
